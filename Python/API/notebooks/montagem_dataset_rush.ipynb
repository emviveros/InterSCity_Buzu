{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de linhas de ônibus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa dependências\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Importa o módulo api_olhovivo e autentica no Olho Vivo API\n",
    "import sys\n",
    "sys.path.insert(0, '../modules')\n",
    "import api_olhovivo\n",
    "\n",
    "def autenticar_api():\n",
    "    load_dotenv()  # Carrega as variáveis de ambiente do arquivo .env\n",
    "    # Acesse o token de API do arquivo .env\n",
    "    api_token = os.getenv(\"API_TOKEN\")\n",
    "    api = api_olhovivo.OlhoVivoAPI(api_token)\n",
    "    return api\n",
    "\n",
    "def run_posicao_veiculos_at_interval(interval, duration, max_retries=6, max_failures=3, backoff_factor=2):\n",
    "    start_time = datetime.now()\n",
    "    end_time = start_time\n",
    "    df = pd.DataFrame(columns=['hr', 'c', 'cl', 'sl', 'lt0', 'lt1', 'qv', 'p', 'a', 'ta', 'py', 'px'])\n",
    "    api = autenticar_api()  # Autenticar no início\n",
    "    consecutive_failures = 0  # Contador de falhas consecutivas\n",
    "\n",
    "    while (end_time - start_time).seconds < duration * 60:\n",
    "        result = api.posicao_veiculos()\n",
    "        if result is None:\n",
    "            consecutive_failures += 1\n",
    "            if consecutive_failures >= max_failures:  # Tentar novamente após 3 falhas\n",
    "                num_retries = 0\n",
    "                while result is None and num_retries < max_retries:\n",
    "                    wait_time = backoff_factor ** num_retries  # Cálculo de backoff exponencial\n",
    "                    time.sleep(wait_time)\n",
    "                    api = autenticar_api()\n",
    "                    result = api.posicao_veiculos()\n",
    "                    num_retries += 1\n",
    "                consecutive_failures = 0  # Reiniciar contador se a nova tentativa for bem-sucedida\n",
    "        else:\n",
    "            consecutive_failures = 0  # Reiniciar contador se a requisição for bem-sucedida\n",
    "\n",
    "        if result is not None:\n",
    "            num_retries = 0\n",
    "            \n",
    "            # Extrair hora da consulta\n",
    "            hora_consulta = result['hr']\n",
    "\n",
    "            # Lista para armazenar informações dos veículos\n",
    "            lista_veiculos = []\n",
    "\n",
    "            # Iterar sobre as linhas e veículos\n",
    "            for linha in result['l']:\n",
    "                codigo_linha = linha['c']\n",
    "                codigo_linha_circular = linha['cl']\n",
    "                sentido_linha = linha['sl']\n",
    "                letreiro_0 = linha['lt0']\n",
    "                letreiro_1 = linha['lt1']\n",
    "                quantidade_veiculos = linha['qv']\n",
    "\n",
    "                for veiculo in linha['vs']:\n",
    "                    prefixo = veiculo['p']\n",
    "                    acessivel = veiculo['a']\n",
    "                    data_hora = veiculo['ta']\n",
    "                    latitude = veiculo['py']\n",
    "                    longitude = veiculo['px']\n",
    "\n",
    "                    # Adicionar informações à lista\n",
    "                    lista_veiculos.append({\n",
    "                        'hr': hora_consulta, \n",
    "                        'c': codigo_linha, \n",
    "                        'cl': codigo_linha_circular,\n",
    "                        'sl': sentido_linha,\n",
    "                        'lt0': letreiro_0,\n",
    "                        'lt1': letreiro_1,\n",
    "                        'qv': quantidade_veiculos,\n",
    "                        'p': prefixo,\n",
    "                        'a': acessivel,\n",
    "                        'ta': data_hora,\n",
    "                        'py': latitude,\n",
    "                        'px': longitude\n",
    "                    })\n",
    "\n",
    "            # Converter lista em DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame(lista_veiculos)])\n",
    "        time.sleep(interval * 60)\n",
    "        end_time = datetime.now()\n",
    "    return df\n",
    "\n",
    "def formatar_datahora(datahora_obj):\n",
    "    \"\"\" Formata um objeto Timestamp do Pandas para o formato AAAA-MM-DD hh:mm:ss subtraindo 3 horas. \"\"\"\n",
    "    return (datahora_obj - pd.Timedelta(hours=3)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def arredondar_meio(numero):\n",
    "    \"\"\" Arredonda um número para duas casas decimais usando arredondamento usual. \"\"\"\n",
    "    return round(numero, 4)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dataframe_to_textfile(dataframe, filename_base, columns):\n",
    "    \"\"\"\n",
    "    Salva colunas específicas de um DataFrame em dois arquivos de texto: um com separador de espaço e outro com formatação específica.\n",
    "\n",
    "    Argumentos:\n",
    "        dataframe: O DataFrame do Pandas que contém os dados.\n",
    "        filename_base: O nome base para os arquivos de saída (sem sufixos).\n",
    "        columns: Uma lista de nomes de colunas a serem salvas nos arquivos.\n",
    "\n",
    "    Levanta:\n",
    "        ValueError: Se alguma das colunas especificadas estiver faltando no DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verificação de erro para colunas ausentes\n",
    "    if not all(col in dataframe.columns for col in columns):\n",
    "        ausentes = [col for col in columns if col not in dataframe.columns]\n",
    "        raise ValueError(f\"Colunas ausentes: {', '.join(ausentes)}\")\n",
    "\n",
    "    # Etapas de processamento de dados\n",
    "    dataframe['ta'] = pd.to_datetime(dataframe['ta'])\n",
    "    dataframe.sort_values(by='ta', inplace=True)\n",
    "    dataframe = dataframe.drop_duplicates(subset=['ta', 'p'], keep='last')\n",
    "\n",
    "    # Certifique-se de que \"c\" está incluído na lista de colunas\n",
    "    if \"c\" not in columns:\n",
    "        columns.append(\"c\")\n",
    "\n",
    "    # Selecionar e formatar colunas (se necessário)\n",
    "    ordem_desejada = [\"ta\", \"px\", \"py\", \"p\", \"c\", \"lt0\"]\n",
    "    df_subset = dataframe[ordem_desejada].copy()\n",
    "\n",
    "    for col in ordem_desejada:\n",
    "        if col == \"ta\":\n",
    "            df_subset[col] = df_subset[col].apply(formatar_datahora)\n",
    "        elif col == \"c\":\n",
    "            df_subset[col] = df_subset[col].astype(str)\n",
    "        elif col in (\"py\", \"px\"):\n",
    "            df_subset[col] = df_subset[col].apply(arredondar_meio)\n",
    "\n",
    "    # Função para adicionar ponto e vírgula no final de cada linha\n",
    "    def save_with_semicolon(filename, sep):\n",
    "        with open(filename, 'w') as file:\n",
    "            for line in df_subset.to_csv(index=False, sep=sep).split('\\n'):\n",
    "                if line.strip():\n",
    "                    file.write(line + ';\\n')\n",
    "\n",
    "    # Função para numerar linhas e formatar colunas com espaço como separador\n",
    "    def save_with_custom_format(filename):\n",
    "        with open(filename, 'w') as file:\n",
    "            for idx, row in enumerate(df_subset.itertuples(index=False), 1):\n",
    "                formatted_row = ' '.join(map(str, row))\n",
    "                file.write(f\"{idx}, {formatted_row};\\n\")\n",
    "\n",
    "    # Gerar o primeiro arquivo (separador de espaço)\n",
    "    filename_pd = filename_base + \"_pd.txt\"\n",
    "    save_with_semicolon(filename_pd, sep=\"\\t\")\n",
    "\n",
    "    # Gerar o segundo arquivo (numerado, colunas separadas por espaço, linhas terminadas com ponto e vírgula)\n",
    "    filename_max = filename_base + \"_max.txt\"\n",
    "    save_with_custom_format(filename_max)\n",
    "\n",
    "\n",
    "def schedule_function(function, run_date, run_time):\n",
    "  \"\"\"\n",
    "  Agenda a execução de uma função em um horário e data específicos e retorna o valor retornado pela função.\n",
    "\n",
    "  Args:\n",
    "      function: A função a ser executada.\n",
    "      run_date: A data para executar a função, no formato \"DD/MM/YYYY\".\n",
    "      run_time: O horário para executar a função, no formato \"HH:MM\".\n",
    "\n",
    "  Returns:\n",
    "      O valor retornado pela função executada.\n",
    "  \"\"\"\n",
    "\n",
    "  while True:\n",
    "    now = datetime.now()\n",
    "    current_date = now.strftime(\"%d/%m/%Y\")\n",
    "    current_time = now.strftime(\"%H:%M\")\n",
    "    \n",
    "    if current_date == run_date and current_time == run_time:\n",
    "      return function() # Retorna o valor retornado pela função\n",
    "    \n",
    "    time.sleep(1) # Aguarda 1 segundo antes de verificar novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_posicao_veiculos_at_interval(0.15, 0.25)\n",
    "dataframe_to_textfile(df, \"dados_rush\", [\"ta\", \"py\", \"px\", \"p\", \"lt0\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = schedule_function(lambda: run_posicao_veiculos_at_interval(0.2, 120), \"11/05/2024\", \"02:40\")\n",
    "df1.to_json('rush_da_madrudaga_sabado.json', orient='records', indent=4)\n",
    "dataframe_to_textfile(df1, \"rush_da_madrugada_sabado_2024-05-11.txt\", [\"ta\", \"py\", \"px\", \"p\", \"lt0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_json('rush_da_madrudaga_sabado.json')\n",
    "dataframe_to_textfile(df3, \"rush_da_madrugada_sabado_2024-05-11.txt\", [\"ta\", \"py\", \"px\", \"p\", \"lt0\"])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de Velocidades Médias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "\n",
    "def extract_kml_from_kmz(kmz_pathway):\n",
    "    \"\"\"\n",
    "    Extrai o arquivo KML de um arquivo KMZ.\n",
    "\n",
    "    Args:\n",
    "        kmz_pathway: O caminho para o arquivo KMZ.\n",
    "\n",
    "    Returns:\n",
    "        O conteúdo do arquivo KML como uma string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with ZipFile(kmz_pathway, 'r') as kmz:\n",
    "            # List all files in the KMZ archive\n",
    "            unzip_file_list = kmz.namelist()\n",
    "            # Get the KML file\n",
    "            kml_file_name = 'TBC.kml' if 'TBC.kml' in unzip_file_list else unzip_file_list[0]\n",
    "            # Open and read the KML file\n",
    "            with kmz.open(kml_file_name, 'r') as kml_file:\n",
    "                kml_content = kml_file.read().decode('utf-8')\n",
    "            \n",
    "            return kml_content\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def parse_description(description):\n",
    "    \"\"\"\n",
    "    Analisa a string de descrição em um dicionário estruturado, substituindo valores vazios, \"0\" e \"--\" por \"-1\".\n",
    "    Garante que todas as chaves estejam presentes no dicionário final.\n",
    "\n",
    "    Argumentos:\n",
    "        description: A string de descrição de um Placemark.\n",
    "\n",
    "    Retorna:\n",
    "        Um dicionário com a descrição estruturada.\n",
    "    \"\"\"\n",
    "    description_dict = {}\n",
    "    parts = description.split(';')\n",
    "\n",
    "    # Função para tratar valores especiais\n",
    "    def tratar_valor(value):\n",
    "        if value in {\"\", \"0\", \"--\"}:\n",
    "            return -1\n",
    "        return value\n",
    "\n",
    "    # Map description parts to dictionary keys\n",
    "    for i in range(0, len(parts) - 1, 2):\n",
    "        key = parts[i].strip().rstrip(':')\n",
    "        value = parts[i + 1].strip()\n",
    "        value = tratar_valor(value)\n",
    "\n",
    "        if key == 'Trecho':\n",
    "            description_dict['trecho'] = value\n",
    "        elif key == 'Referência':\n",
    "            description_dict['referencia'] = value\n",
    "        elif key == 'Extensão (metros)':\n",
    "            try:\n",
    "                description_dict['extensao_metros'] = int(value.replace('.', '')) if isinstance(value, str) else value\n",
    "            except ValueError:\n",
    "                description_dict['extensao_metros'] = tratar_valor(value)  # Preserve original value if not a number\n",
    "        elif key == 'Velocidade média do trecho':\n",
    "            try:\n",
    "                description_dict['velocidade_media_trecho_kmh'] = int(value.split()[0]) if isinstance(value, str) else value\n",
    "            except ValueError:\n",
    "                description_dict['velocidade_media_trecho_kmh'] = tratar_valor(value)  # Preserve original value if not a number\n",
    "        elif key == 'Tempo médio do percurso':\n",
    "            try:\n",
    "                if isinstance(value, str):\n",
    "                    hours, minutes = map(int, value.split('h'))\n",
    "                    total_minutes = hours * 60 + minutes\n",
    "                    description_dict['tempo_medio_percurso_minutos'] = total_minutes\n",
    "                else:\n",
    "                    description_dict['tempo_medio_percurso_minutos'] = value\n",
    "            except ValueError:\n",
    "                description_dict['tempo_medio_percurso_minutos'] = tratar_valor(value)  # Preserve original value if not a valid time format\n",
    "        elif key == 'Velocidade média do corredor':\n",
    "            try:\n",
    "                description_dict['velocidade_media_corredor_kmh'] = int(value.split()[0]) if isinstance(value, str) else value\n",
    "            except ValueError:\n",
    "                description_dict['velocidade_media_corredor_kmh'] = tratar_valor(value)  # Preserve original value if not a number\n",
    "\n",
    "    # Garantir que todas as chaves estejam presentes\n",
    "    required_keys = ['trecho', 'referencia', 'extensao_metros', 'velocidade_media_trecho_kmh', 'tempo_medio_percurso_minutos', 'velocidade_media_corredor_kmh']\n",
    "    for key in required_keys:\n",
    "        if key not in description_dict:\n",
    "            description_dict[key] = -1\n",
    "\n",
    "    return description_dict\n",
    "\n",
    "\n",
    "def read_kml_content(kml_content):\n",
    "    \"\"\"\n",
    "    Extrai dados de texto das descrições e coordenadas de todos os Placemarks de um arquivo KML, preservando o texto e removendo tags e entidades HTML.\n",
    "    Usa o ponto e vírgula como separador entre diferentes descrições.\n",
    "\n",
    "    Args:\n",
    "        kml_content: O conteúdo do arquivo KML como uma string.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de dicionários com descrições e coordenadas para cada Placemark.\n",
    "    \"\"\"\n",
    "    placemarks = []\n",
    "    for placemark in kml_content.split('<Placemark'):\n",
    "        if not placemark.strip():\n",
    "            continue\n",
    "        \n",
    "        placemark_data = {}\n",
    "        \n",
    "        # Extract description\n",
    "        description_start = placemark.find('<description>')\n",
    "        description_end = placemark.find('</description>')\n",
    "        if description_start != -1 and description_end != -1:\n",
    "            description = placemark[description_start + len('<description>'): description_end]\n",
    "            description = html.unescape(description)\n",
    "            soup = BeautifulSoup(description, 'html.parser')\n",
    "            text_only_description = soup.get_text(separator=';', strip=True)\n",
    "            structured_description = parse_description(text_only_description)\n",
    "            placemark_data.update(structured_description)  # Merge description keys into placemark_data\n",
    "\n",
    "        # Extract coordinates\n",
    "        coordinates_start = placemark.find('<coordinates>')\n",
    "        coordinates_end = placemark.find('</coordinates>')\n",
    "        if coordinates_start != -1 and coordinates_end != -1:\n",
    "            coordinates = placemark[coordinates_start + len('<coordinates>'): coordinates_end]\n",
    "            coordinates = coordinates.strip().split()\n",
    "            coordinates = [coord.split(',')[:2] for coord in coordinates]  # Discarding the third value\n",
    "            placemark_data['coordenadas'] = coordinates\n",
    "        else:\n",
    "            placemark_data['coordenadas'] = -1\n",
    "\n",
    "        placemarks.append(placemark_data)\n",
    "    \n",
    "    return placemarks\n",
    "\n",
    "def exportar_velocidades_medias_Pd(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        # Write the header\n",
    "        headers = ['trecho', 'referencia', 'extensao_metros', 'velocidade_media_trecho_kmh', 'tempo_medio_percurso_minutos', 'velocidade_media_corredor_kmh', 'coordenadas']\n",
    "        file.write(' '.join(headers) + '\\n')\n",
    "        \n",
    "        for placemark in data:\n",
    "            trecho = f\"\\\"{placemark['trecho']}\\\"\" if placemark['trecho'] != -1 else \"-1\"\n",
    "            referencia = f\"\\\"{placemark['referencia']}\\\"\" if placemark['referencia'] != -1 else \"-1\"\n",
    "            extensao = placemark['extensao_metros']\n",
    "            velocidade_trecho = placemark['velocidade_media_trecho_kmh']\n",
    "            tempo_percurso = placemark['tempo_medio_percurso_minutos']\n",
    "            velocidade_corredor = placemark['velocidade_media_corredor_kmh']\n",
    "\n",
    "            # Agrupar coordenadas em pares\n",
    "            if placemark['coordenadas'] != -1:\n",
    "                coordenadas_list = placemark['coordenadas']\n",
    "                coordenadas_pares = [f\"{coord[0]} {coord[1]}\" for coord in coordenadas_list]\n",
    "                coordenadas = ','.join(coordenadas_pares)\n",
    "            else:\n",
    "                coordenadas = \"-1\"\n",
    "\n",
    "            file.write(f\"{trecho} {referencia} {extensao} {velocidade_trecho} {tempo_percurso} {velocidade_corredor} {coordenadas}\\n\")\n",
    "\n",
    "def exportar_velocidades_medias_Max(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for idx, placemark in enumerate(data, start=1):\n",
    "            trecho = f\"\\\"{placemark['trecho']}\\\"\" if placemark['trecho'] != -1 else \"-1\"\n",
    "            referencia = f\"\\\"{placemark['referencia']}\\\"\" if placemark['referencia'] != -1 else \"-1\"\n",
    "            extensao = placemark['extensao_metros']\n",
    "            velocidade_trecho = placemark['velocidade_media_trecho_kmh']\n",
    "            tempo_percurso = placemark['tempo_medio_percurso_minutos']\n",
    "            velocidade_corredor = placemark['velocidade_media_corredor_kmh']\n",
    "\n",
    "            # Agrupar coordenadas em pares\n",
    "            if placemark['coordenadas'] != -1:\n",
    "                coordenadas_list = placemark['coordenadas']\n",
    "                coordenadas_pares = [f\"{coord[0]} {coord[1]}\" for coord in coordenadas_list]\n",
    "                coordenadas = ','.join(coordenadas_pares)\n",
    "                coordenadas = f\"\\\"{coordenadas}\\\"\"\n",
    "            else:\n",
    "                coordenadas = \"\\\"-1\\\"\"\n",
    "\n",
    "            file.write(f\"{idx}, {trecho} {referencia} {extensao} {velocidade_trecho} {tempo_percurso} {velocidade_corredor} {coordenadas};\\n\")\n",
    "\n",
    "def exportar_datasets(data, filename_base):\n",
    "    exportar_velocidades_medias_Pd(data, f\"{filename_base}_Pd.txt\")\n",
    "    exportar_velocidades_medias_Max(data, f\"{filename_base}_Max.txt\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = autenticar_api()\n",
    "\n",
    "kmz_pathway = api.velocidade_media_cidade(\"BC\")\n",
    "\n",
    "# Extrai o conteúdo do arquivo KML do arquivo KMZ\n",
    "kml_content = extract_kml_from_kmz(kmz_pathway)\n",
    "\n",
    "# Lê o conteúdo do arquivo KML e extrai as descrições e coordenadas\n",
    "trechos = read_kml_content(kml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar_datasets(trechos, \"velocidades_médias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_trechos = pd.DataFrame(trechos)\n",
    "df_trechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
